{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x1112f2c90>"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "import torch.autograd as autograd\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "torch.manual_seed(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "def argmax(vec):\n",
        "    # return the argmax as a python int\n",
        "    _, idx = torch.max(vec, 1)\n",
        "    return idx.item()\n",
        "\n",
        "\n",
        "def prepare_sequence(seq, to_ix):\n",
        "    idxs = [to_ix[w] for w in seq]\n",
        "    return torch.tensor(idxs, dtype=torch.long)\n",
        "\n",
        "\n",
        "# Compute log sum exp in a numerically stable way for the forward algorithm\n",
        "def log_sum_exp(vec):\n",
        "    max_score = vec[0, argmax(vec)]\n",
        "    max_score_broadcast = max_score.view(1, -1).expand(1, vec.size()[1])\n",
        "    return max_score + \\\n",
        "        torch.log(torch.sum(torch.exp(vec - max_score_broadcast)))\n",
        "\n",
        "class BiLSTM_CRF(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, tag_to_ix, embedding_dim, hidden_dim):\n",
        "        super(BiLSTM_CRF, self).__init__()\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.vocab_size = vocab_size\n",
        "        self.tag_to_ix = tag_to_ix\n",
        "        self.tagset_size = len(tag_to_ix)\n",
        "\n",
        "        self.word_embeds = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim // 2,\n",
        "                            num_layers=1, bidirectional=True)\n",
        "\n",
        "        # Maps the output of the LSTM into tag space.\n",
        "        self.hidden2tag = nn.Linear(hidden_dim, self.tagset_size)\n",
        "\n",
        "        # Matrix of transition parameters.  Entry i,j is the score of\n",
        "        # transitioning *to* i *from* j.\n",
        "        self.transitions = nn.Parameter(\n",
        "            torch.randn(self.tagset_size, self.tagset_size))\n",
        "\n",
        "        # These two statements enforce the constraint that we never transfer\n",
        "        # to the start tag and we never transfer from the stop tag\n",
        "        self.transitions.data[tag_to_ix[START_TAG], :] = -10000\n",
        "        self.transitions.data[:, tag_to_ix[STOP_TAG]] = -10000\n",
        "\n",
        "        self.hidden = self.init_hidden()\n",
        "\n",
        "    def init_hidden(self):\n",
        "        return (torch.randn(2, 1, self.hidden_dim // 2),\n",
        "                torch.randn(2, 1, self.hidden_dim // 2))\n",
        "\n",
        "    def _forward_alg(self, feats):\n",
        "        # Do the forward algorithm to compute the partition function\n",
        "        init_alphas = torch.full((1, self.tagset_size), -10000.)\n",
        "        # START_TAG has all of the score.\n",
        "        init_alphas[0][self.tag_to_ix[START_TAG]] = 0.\n",
        "\n",
        "        # Wrap in a variable so that we will get automatic backprop\n",
        "        forward_var = init_alphas\n",
        "\n",
        "        # Iterate through the sentence\n",
        "        for feat in feats:\n",
        "            alphas_t = []  # The forward tensors at this timestep\n",
        "            for next_tag in range(self.tagset_size):\n",
        "                # broadcast the emission score: it is the same regardless of\n",
        "                # the previous tag\n",
        "                emit_score = feat[next_tag].view(\n",
        "                    1, -1).expand(1, self.tagset_size)\n",
        "                # the ith entry of trans_score is the score of transitioning to\n",
        "                # next_tag from i\n",
        "                trans_score = self.transitions[next_tag].view(1, -1)\n",
        "                # The ith entry of next_tag_var is the value for the\n",
        "                # edge (i -> next_tag) before we do log-sum-exp\n",
        "                next_tag_var = forward_var + trans_score + emit_score\n",
        "                # The forward variable for this tag is log-sum-exp of all the\n",
        "                # scores.\n",
        "                alphas_t.append(log_sum_exp(next_tag_var).view(1))\n",
        "            forward_var = torch.cat(alphas_t).view(1, -1)\n",
        "        terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]\n",
        "        alpha = log_sum_exp(terminal_var)\n",
        "        return alpha\n",
        "\n",
        "    def _get_lstm_features(self, sentence):\n",
        "        self.hidden = self.init_hidden()\n",
        "        embeds = self.word_embeds(sentence).view(len(sentence), 1, -1)\n",
        "        lstm_out, self.hidden = self.lstm(embeds, self.hidden)\n",
        "        lstm_out = lstm_out.view(len(sentence), self.hidden_dim)\n",
        "        lstm_feats = self.hidden2tag(lstm_out)\n",
        "        return lstm_feats\n",
        "\n",
        "    def _score_sentence(self, feats, tags):\n",
        "        # Gives the score of a provided tag sequence\n",
        "        score = torch.zeros(1)\n",
        "        tags = torch.cat([torch.tensor([self.tag_to_ix[START_TAG]], dtype=torch.long), tags])\n",
        "        for i, feat in enumerate(feats):\n",
        "            score = score + \\\n",
        "                self.transitions[tags[i + 1], tags[i]] + feat[tags[i + 1]]\n",
        "        score = score + self.transitions[self.tag_to_ix[STOP_TAG], tags[-1]]\n",
        "        return score\n",
        "\n",
        "    def _viterbi_decode(self, feats):\n",
        "        backpointers = []\n",
        "\n",
        "        # Initialize the viterbi variables in log space\n",
        "        init_vvars = torch.full((1, self.tagset_size), -10000.)\n",
        "        init_vvars[0][self.tag_to_ix[START_TAG]] = 0\n",
        "\n",
        "        # forward_var at step i holds the viterbi variables for step i-1\n",
        "        forward_var = init_vvars\n",
        "        for feat in feats:\n",
        "            bptrs_t = []  # holds the backpointers for this step\n",
        "            viterbivars_t = []  # holds the viterbi variables for this step\n",
        "\n",
        "            for next_tag in range(self.tagset_size):\n",
        "                # next_tag_var[i] holds the viterbi variable for tag i at the\n",
        "                # previous step, plus the score of transitioning\n",
        "                # from tag i to next_tag.\n",
        "                # We don't include the emission scores here because the max\n",
        "                # does not depend on them (we add them in below)\n",
        "                next_tag_var = forward_var + self.transitions[next_tag]\n",
        "                best_tag_id = argmax(next_tag_var)\n",
        "                bptrs_t.append(best_tag_id)\n",
        "                viterbivars_t.append(next_tag_var[0][best_tag_id].view(1))\n",
        "            # Now add in the emission scores, and assign forward_var to the set\n",
        "            # of viterbi variables we just computed\n",
        "            forward_var = (torch.cat(viterbivars_t) + feat).view(1, -1)\n",
        "            backpointers.append(bptrs_t)\n",
        "\n",
        "        # Transition to STOP_TAG\n",
        "        terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]\n",
        "        best_tag_id = argmax(terminal_var)\n",
        "        path_score = terminal_var[0][best_tag_id]\n",
        "\n",
        "        # Follow the back pointers to decode the best path.\n",
        "        best_path = [best_tag_id]\n",
        "        for bptrs_t in reversed(backpointers):\n",
        "            best_tag_id = bptrs_t[best_tag_id]\n",
        "            best_path.append(best_tag_id)\n",
        "        # Pop off the start tag (we dont want to return that to the caller)\n",
        "        start = best_path.pop()\n",
        "        assert start == self.tag_to_ix[START_TAG]  # Sanity check\n",
        "        best_path.reverse()\n",
        "        return path_score, best_path\n",
        "\n",
        "    def neg_log_likelihood(self, sentence, tags):\n",
        "        feats = self._get_lstm_features(sentence)\n",
        "        forward_score = self._forward_alg(feats)\n",
        "        gold_score = self._score_sentence(feats, tags)\n",
        "        return forward_score - gold_score\n",
        "\n",
        "    def forward(self, sentence):  # dont confuse this with _forward_alg above.\n",
        "        # Get the emission scores from the BiLSTM\n",
        "        lstm_feats = self._get_lstm_features(sentence)\n",
        "\n",
        "        # Find the best path, given the features.\n",
        "        score, tag_seq = self._viterbi_decode(lstm_feats)\n",
        "        # return score, tag_seq\n",
        "        return tag_seq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# data\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "PARTICIPANT_ID = 1 #4348\n",
        "\n",
        "df_csv=pd.read_csv('/Users/apple/Desktop/deep_eye/dataset/input_right.csv',usecols=['participant_ID','Q_ID','text','fixation1'])\n",
        "df_csv=df_csv[(df_csv['participant_ID']==PARTICIPANT_ID)] # take 1st participant data\n",
        "df_csv=df_csv.drop(['participant_ID'],axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " [['沙罐', '置入', '不同', '濃度', '鹽水', '中', '所', '受', '浮力', '會', '如何', '相同', '濃度', '愈', '高', '所', '受', '浮力', '愈', '大', '濃度', '愈', '高', '所', '受', '浮力', '愈', '小'], [0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1]] \n",
            " ['沙罐', '置入', '不同', '濃度', '鹽水', '中', '所', '受', '浮力', '會', '如何', '相同', '濃度', '愈', '高', '所', '受', '浮力', '愈', '大', '濃度', '愈', '高', '所', '受', '浮力', '愈', '小'] \n",
            " [0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1]\n"
          ]
        }
      ],
      "source": [
        "q_index_list = sorted(list(set(df_csv['Q_ID'])))\n",
        "\n",
        "total_q_list = []\n",
        "for q in q_index_list:\n",
        "    df_q = df_csv[df_csv['Q_ID'] == q]\n",
        "    text_list = list(df_q['text'])\n",
        "    label_list = list(df_q['fixation1'])\n",
        "    q_list = [text_list, label_list]\n",
        "    total_q_list.append(q_list)\n",
        "\n",
        "print(\n",
        "    '\\n',total_q_list[0], # first data with text and label\n",
        "    '\\n',total_q_list[0][0], # first data's text\n",
        "    '\\n',total_q_list[0][1], # first data's label\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "real label：[0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1]\n",
            "untrained label prediction：[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "=============start BiLSTM+CRF model training=============\n",
            "the0th epoch Loss:20.18512725830078\n",
            "the50th epoch Loss:12.962231636047363\n",
            "the100th epoch Loss:8.370246887207031\n",
            "the150th epoch Loss:4.185600280761719\n",
            "=============trained model saved=============\n",
            "\n",
            "\n",
            "=============load trained model and predict=============\n",
            "trained label prediction：[0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1]\n"
          ]
        }
      ],
      "source": [
        "START_TAG = \"<START>\"\n",
        "STOP_TAG = \"<STOP>\"\n",
        "EMBEDDING_DIM = 4 #5\n",
        "HIDDEN_DIM = 4 #4\n",
        "\n",
        "train_num = int(len(q_index_list)*0.8)\n",
        "training_data = total_q_list[:train_num]\n",
        "testing_data = total_q_list[train_num:]\n",
        "\n",
        "# word_to_ix # unique word and its representing number\n",
        "word_to_ix = {}\n",
        "for sentence, tags in training_data:\n",
        "    for word in sentence:\n",
        "        if word not in word_to_ix:\n",
        "            word_to_ix[word] = len(word_to_ix)\n",
        "\n",
        "tag_to_ix = {0: 0, 1: 1, START_TAG: 2, STOP_TAG: 3}\n",
        "\n",
        "model = BiLSTM_CRF(len(word_to_ix), tag_to_ix, EMBEDDING_DIM, HIDDEN_DIM)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, weight_decay=1e-4)\n",
        "\n",
        "# Check predictions before training\n",
        "with torch.no_grad():\n",
        "    precheck_sent = prepare_sequence(training_data[0][0], word_to_ix)\n",
        "    precheck_tags = torch.tensor([tag_to_ix[t] for t in training_data[0][1]], dtype=torch.long)\n",
        "    print('real label：'+ str(precheck_tags.tolist()))\n",
        "    print('untrained label prediction：'+ str(model(precheck_sent)))\n",
        "\n",
        "print('=============start BiLSTM+CRF model training=============')\n",
        "# Make sure prepare_sequence from earlier in the LSTM section is loaded\n",
        "for epoch in range(200):  # again, normally you would NOT do 300 epochs, it is toy data\n",
        "    for sentence, tags in training_data:\n",
        "        # Step 1. Remember that Pytorch accumulates gradients.\n",
        "        # We need to clear them out before each instance\n",
        "        model.zero_grad()\n",
        "\n",
        "        # Step 2. Get our inputs ready for the network, that is,\n",
        "        # turn them into Tensors of word indices.\n",
        "        sentence_in = prepare_sequence(sentence, word_to_ix)\n",
        "        targets = torch.tensor([tag_to_ix[t] for t in tags], dtype=torch.long)\n",
        "\n",
        "        # Step 3. Run our forward pass.\n",
        "        loss = model.neg_log_likelihood(sentence_in, targets)\n",
        "\n",
        "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
        "        # calling optimizer.step()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    if epoch%50 == 0:\n",
        "        print(f'the{epoch}th epoch Loss:{loss[0]}')\n",
        "\n",
        "\n",
        "output_path = 'ner_trained_model.cpt'\n",
        "torch.save(model, output_path)\n",
        "print('=============trained model saved=============\\n\\n')\n",
        "\n",
        "\n",
        "\n",
        "print('=============load trained model and predict=============')\n",
        "model_path = 'ner_trained_model.cpt'\n",
        "trained_ner_model = torch.load(model_path)\n",
        "with torch.no_grad():\n",
        "    precheck_sent = prepare_sequence(training_data[0][0], word_to_ix)\n",
        "    print('trained label prediction：' + str(model(precheck_sent)))\n",
        "\n",
        "# time spent : 3min"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # accuracy from scratch\n",
        "# total_wrong = []\n",
        "# acccuracy_score = []\n",
        "# for q in range(47):\n",
        "#     precheck_sent = prepare_sequence(training_data[q][0], word_to_ix)\n",
        "#     predict = model(precheck_sent)\n",
        "#     answer = training_data[q][1]\n",
        "#     accuracy = sum([1 for i,j in zip(predict,answer) if i==j])/len(answer)\n",
        "#     print(str(q+1) + \" accuracy:\", round(accuracy,2))\n",
        "#     acccuracy_score.append(accuracy)\n",
        "#     wrong_list = [i for i,j in zip(predict,answer) if i!=j] # wrong answer\n",
        "#     total_wrong.append(wrong_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['沙罐', '置入', '不同', '濃度', '鹽水', '中', '所', '受', '浮力', '會', '如何', '相同', '濃度', '愈', '高', '所', '受', '浮力', '愈', '大', '濃度', '愈', '高', '所', '受', '浮力', '愈', '小']\n",
            "[0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1]\n",
            "[0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1]\n",
            "===============================\n",
            "['外加', '電池', '將', '碳棒', '及', '銅棒', '放入', '硫酸銅', '𥚃', '將', '發生', '什麼', '反應', '電解', '反應', '電池', '反應', '氧化還原', '反應']\n",
            "[0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1]\n",
            "[0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1]\n",
            "===============================\n",
            "['以', '針筒', '吸取', '熱水', '並', '封住', '針頭', '將', '針頭', '活塞', '向', '外', '拉出', '裡面', '的', '水', '會', '有', '何', '現象', '水位', '不變', '水', '沸騰', '水', '向', '上', '四散', '各', '處']\n",
            "[0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0]\n",
            "[0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0]\n",
            "===============================\n",
            "['雌蕊', '的', '花柱', '內', '有', '多少', '個', '花粉管', '一', '個', '兩', '個', '很多', '個']\n",
            "[0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0]\n",
            "[0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0]\n",
            "===============================\n",
            "['A', '和', 'B', '燈泡', '並聯', '並', '與', 'C', '燈泡', '串聯', '這', 'A', 'B', 'C', '三', '個', '燈泡', '的', '亮度', '大小', '何者', '正確', 'A', '>', 'B', '>', 'C', 'A', '=', 'B', '>', 'C', 'A', '=', 'B', '<', 'C']\n",
            "[0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1]\n",
            "[0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0]\n",
            "===============================\n",
            "['將', '罐子', '綁上', '乒乓球', '當', '往', '右', '移動', '罐子', '罐', '內', '乒乓球', '會', '有', '何', '現象', '向', '右', '跑', '向', '左', '跑', '停', '在', '原處', '不', '動']\n",
            "[0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0]\n",
            "[0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0]\n",
            "===============================\n",
            "['在', '兩', '個', '懸掛', '的', '氣球', '中間', '用', '吹風機', '吹氣', '請問', '氣球', '會', '有', '什麼', '變化', '兩', '球', '分開', '兩', '球', '靠近', '兩', '球', '位置', '不變']\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0]\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0]\n",
            "===============================\n",
            "['在', '鋅銅電池', '反應', '中', '檢流計', '指針', '的', '指向', '電子流向', '是', '向', '左', '不', '流動', '向', '右']\n",
            "[0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1]\n",
            "[0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1]\n",
            "===============================\n",
            "['在', '封閉', '針筒', '中', '置入', '一', '小', '氣球', '將', '活塞', '向', '外', '拉', '後', '氣球', '會', '有', '何', '變化', '氣球', '縮小', '氣球', '脹大', '氣球', '大小', '不變']\n",
            "[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0]\n",
            "[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0]\n",
            "===============================\n",
            "['同', '植株', '兩', '片', '葉子', '分別', '套入', '碳酸氫鈉', '與', '氫氧化鈉', '水溶液', '袋中', '光照', '數日', '後', '有無', '澱粉', '反應', '僅', '碳酸氫鈉', '組', '有', '澱粉', '反應', '僅', '氫氧化鈉', '組', '有', '澱粉', '反應', '兩', '者', '皆', '有', '澱粉', '反應']\n",
            "[0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0]\n",
            "[0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0]\n",
            "===============================\n",
            "['砝碼', '置於', '一', '個', '和', '串聯', '二', '個', '相同', '的', '彈簧', '下', '不計', '彈簧', '重量', 'A', 'B', 'C', '彈簧', '伸長量', '一', '個', '彈簧', 'C', '比較', '長', '串聯', '之', '彈簧', 'A', '和', 'B', '比較', '長', 'A', '=', 'B', '=', 'C']\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1]\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1]\n",
            "===============================\n",
            "['將', '金屬', '銅', '放', '在', '硫酸銅', '溶液', '中', '會', '發生', '什麼', '反應', '產生', '電流', '不', '產生', '電流', '產生', '新', '物質']\n",
            "[0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1]\n",
            "[0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0]\n",
            "===============================\n",
            "['水', '沸騰', '後', '將', '火', '移開', '封住', '瓶口', '澆', '冷水', '瓶', '內', '水', '會', '如何', '沸騰', '凝結', '不會', '改變']\n",
            "[0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1]\n",
            "[0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1]\n",
            "===============================\n",
            "['攀藤植物', '沒有', '支撐物', '時', '會', '如何', '生長', '會', '依', '在', '地面上', '長', '會', '直直', '向', '上', '長', '會', '旋轉', '向', '上', '長']\n",
            "[0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0]\n",
            "[0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0]\n",
            "===============================\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "\n",
        "# training predict score\n",
        "total_result_list = []\n",
        "for q in range(len(training_data)):\n",
        "    precheck_sent = prepare_sequence(training_data[q][0], word_to_ix)\n",
        "    predict = model(precheck_sent)\n",
        "    answer = training_data[q][1]\n",
        "    print(training_data[q][0])\n",
        "    print(predict)\n",
        "    print(answer)\n",
        "    print(\"===============================\")\n",
        "    accuracy = accuracy_score(answer, predict)\n",
        "    precision = precision_score(answer, predict)\n",
        "    recall = recall_score(answer, predict)\n",
        "    f1score = f1_score(answer, predict)\n",
        "    result_list = [accuracy, precision, recall, f1score]\n",
        "    result_list = [round(elem, 2) for elem in result_list]\n",
        "    total_result_list.append(result_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>accuracy</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.96</td>\n",
              "      <td>0.94</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.97</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.95</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.92</td>\n",
              "      <td>0.96</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.97</td>\n",
              "      <td>0.93</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.96</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.86</td>\n",
              "      <td>0.80</td>\n",
              "      <td>0.80</td>\n",
              "      <td>0.80</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.86</td>\n",
              "      <td>0.86</td>\n",
              "      <td>0.80</td>\n",
              "      <td>0.83</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.92</td>\n",
              "      <td>0.82</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.90</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.83</td>\n",
              "      <td>0.77</td>\n",
              "      <td>0.77</td>\n",
              "      <td>0.77</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0.97</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.92</td>\n",
              "      <td>0.96</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0.85</td>\n",
              "      <td>0.83</td>\n",
              "      <td>0.91</td>\n",
              "      <td>0.87</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0.95</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.91</td>\n",
              "      <td>0.95</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    accuracy  precision  recall  f1score\n",
              "0       0.96       0.94    1.00     0.97\n",
              "1       0.95       1.00    0.92     0.96\n",
              "2       0.97       0.93    1.00     0.96\n",
              "3       0.86       0.80    0.80     0.80\n",
              "4       0.86       0.86    0.80     0.83\n",
              "5       1.00       1.00    1.00     1.00\n",
              "6       0.92       0.82    1.00     0.90\n",
              "7       1.00       1.00    1.00     1.00\n",
              "8       1.00       1.00    1.00     1.00\n",
              "9       0.83       0.77    0.77     0.77\n",
              "10      0.97       1.00    0.92     0.96\n",
              "11      0.85       0.83    0.91     0.87\n",
              "12      1.00       1.00    1.00     1.00\n",
              "13      0.95       1.00    0.91     0.95"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "total_result_df = pd.DataFrame(total_result_list)\n",
        "total_result_df.columns = ['accuracy', 'precision', 'recall', 'f1score']\n",
        "total_result_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "accuracy     0.937143\n",
              "precision    0.925000\n",
              "recall       0.930714\n",
              "f1score      0.926429\n",
              "dtype: float64"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "total_result_df.mean(axis=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "testing data show"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "# for testing data\n",
        "test_word_to_ix = {}\n",
        "for sentence, tags in testing_data:\n",
        "    for word in sentence:\n",
        "        if word not in test_word_to_ix:\n",
        "            test_word_to_ix[word] = len(test_word_to_ix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['細長', '的', '玻璃管', '裝', '水', '1033.6', 'cm', '同時', '拿掉', '玻璃管', '上', '和', '下', '管', '蓋', '水', '會', '跑出來', '嗎', '會', '不會', '只', '會', '跑出', '一點點']\n",
            "[0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0]\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0]\n",
            "===============================\n",
            "['未成熟', '的', '香蕉', '和', '成熟', '香蕉', '加', '碘液', '後', '哪', '個', '會', '比較', '黑', '呢', '未成熟', '成熟', '一樣', '黑']\n",
            "[0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0]\n",
            "[0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1]\n",
            "===============================\n",
            "['在', '抽氣', '密封罐', '內', '放置', '一', '手套', '將', '罐', '內', '氣體', '抽出', '後', '手套', '會', '有', '何', '變化', '手套', '縮小', '手套', '脹大', '手套', '不變']\n",
            "[0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1]\n",
            "[0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0]\n",
            "===============================\n",
            "['砝碼', '置於', '串聯', '和', '並聯', '的', '二', '個', '相同', '的', '彈簧', '下', '不計', '彈簧', '重量', 'A', 'B', 'C', 'D', '四', '個', '彈簧', '伸長量', '並聯', '之', '彈簧', 'C', 'D', '比較', '長', '串聯', '之', '彈簧', 'A', 'B', '比較', '長', 'A', '=', 'B', '=', 'C', '=', 'D']\n",
            "[0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0]\n",
            "[0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]\n",
            "===============================\n"
          ]
        }
      ],
      "source": [
        "total_result_list = []\n",
        "for q in range(len(testing_data)):\n",
        "    precheck_sent = prepare_sequence(testing_data[q][0], test_word_to_ix)\n",
        "    predict = model(precheck_sent)\n",
        "    answer = testing_data[q][1]\n",
        "    print(testing_data[q][0])\n",
        "    print(predict)\n",
        "    print(answer)\n",
        "    print(\"===============================\")\n",
        "    accuracy = accuracy_score(answer, predict)\n",
        "    precision = precision_score(answer, predict)\n",
        "    recall = recall_score(answer, predict)\n",
        "    f1score = f1_score(answer, predict)\n",
        "    result_list = [accuracy, precision, recall, f1score]\n",
        "    result_list = [round(elem, 2) for elem in result_list]\n",
        "    total_result_list.append(result_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>accuracy</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.44</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.42</td>\n",
              "      <td>0.33</td>\n",
              "      <td>0.57</td>\n",
              "      <td>0.42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.42</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.62</td>\n",
              "      <td>0.42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.52</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.09</td>\n",
              "      <td>0.09</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   accuracy  precision  recall  f1score\n",
              "0      0.44       0.00    0.00     0.00\n",
              "1      0.42       0.33    0.57     0.42\n",
              "2      0.42       0.31    0.62     0.42\n",
              "3      0.52       0.08    0.09     0.09"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "total_result_df = pd.DataFrame(total_result_list)\n",
        "total_result_df.columns = ['accuracy', 'precision', 'recall', 'f1score']\n",
        "total_result_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "accuracy     0.4500\n",
              "precision    0.1800\n",
              "recall       0.3200\n",
              "f1score      0.2325\n",
              "dtype: float64"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "total_result_df.mean(axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # draw confusion matrix\n",
        "# import matplotlib.pyplot as plt\n",
        "# conf_matrix = confusion_matrix(y_true=answer, y_pred=predict)\n",
        "# fig, ax = plt.subplots(figsize=(5, 5))\n",
        "# ax.matshow(conf_matrix, cmap=plt.cm.Oranges, alpha=0.3)\n",
        "# for i in range(conf_matrix.shape[0]):\n",
        "#     for j in range(conf_matrix.shape[1]):\n",
        "#         ax.text(x=j, y=i,s=conf_matrix[i, j], va='center', ha='center', size='xx-large')\n",
        "\n",
        "# plt.xlabel('Predictions', fontsize=18)\n",
        "# plt.ylabel('Actuals', fontsize=18)\n",
        "# plt.title('Confusion Matrix', fontsize=18)\n",
        "# plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "deepeye_env",
      "language": "python",
      "name": "deepeye_env"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
